{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Market Indicators (Kaggle NYSE).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreshthSaxena/Algorithmic-Trading/blob/master/Market_Indicators_(Kaggle_NYSE).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV-flu3w6edU",
        "colab_type": "code",
        "outputId": "7f9fced9-6290-494e-bad3-df31a1637de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adam\n",
        "import keras\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import math, time\n",
        "import tensorflow as tf\n",
        "from pandas_datareader import data as pdr\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "#from clr_callback import *\n",
        "import fix_yahoo_finance"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyzTlwsf6iFW",
        "colab_type": "code",
        "outputId": "c3d37baf-a6d0-4c59-aea2-bb4c434b292b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/bckenstler/CLR\n",
        "%cd CLR\n",
        "from clr_callback import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CLR'...\n",
            "remote: Enumerating objects: 244, done.\u001b[K\n",
            "remote: Total 244 (delta 0), reused 0 (delta 0), pack-reused 244\u001b[K\n",
            "Receiving objects: 100% (244/244), 1.37 MiB | 3.65 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "/content/CLR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMidd_x46mWm",
        "colab_type": "code",
        "outputId": "32517577-7c71-492b-daa7-1ae8cf6e93e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pdr.get_data_yahoo('^GSPC', start=datetime.datetime(2000, 1, 4), end=datetime.datetime(2017, 7, 27))\n",
        "df = df.drop(['Close'],1)\n",
        "df.columns = ['high', 'low', 'open', 'volume', 'adj close']\n",
        "df.reset_index(inplace = True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>adj close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>1455.219971</td>\n",
              "      <td>1397.430054</td>\n",
              "      <td>1455.219971</td>\n",
              "      <td>1009000000</td>\n",
              "      <td>1399.420044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>1413.270020</td>\n",
              "      <td>1377.680054</td>\n",
              "      <td>1399.420044</td>\n",
              "      <td>1085500000</td>\n",
              "      <td>1402.109985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-06</td>\n",
              "      <td>1411.900024</td>\n",
              "      <td>1392.099976</td>\n",
              "      <td>1402.109985</td>\n",
              "      <td>1092300000</td>\n",
              "      <td>1403.449951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-07</td>\n",
              "      <td>1441.469971</td>\n",
              "      <td>1400.729980</td>\n",
              "      <td>1403.449951</td>\n",
              "      <td>1225200000</td>\n",
              "      <td>1441.469971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-10</td>\n",
              "      <td>1464.359985</td>\n",
              "      <td>1441.469971</td>\n",
              "      <td>1441.469971</td>\n",
              "      <td>1064800000</td>\n",
              "      <td>1457.599976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date         high          low         open      volume    adj close\n",
              "0 2000-01-04  1455.219971  1397.430054  1455.219971  1009000000  1399.420044\n",
              "1 2000-01-05  1413.270020  1377.680054  1399.420044  1085500000  1402.109985\n",
              "2 2000-01-06  1411.900024  1392.099976  1402.109985  1092300000  1403.449951\n",
              "3 2000-01-07  1441.469971  1400.729980  1403.449951  1225200000  1441.469971\n",
              "4 2000-01-10  1464.359985  1441.469971  1441.469971  1064800000  1457.599976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuM3U0OY8WKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ema(data, period=0.5, column='adj close'):\n",
        "    data['ema' + str(period)] = data[column].ewm(ignore_na=False, min_periods=period, com=period, adjust=True).mean()\n",
        "    \n",
        "    return data\n",
        "df= ema(df)\n",
        "\n",
        "def macd(data, period_long=26, period_short=12, period_signal=9, column='adj close'):\n",
        "    remove_cols = []\n",
        "    if not 'ema' + str(period_long) in data.columns:\n",
        "        data = ema(data, period_long)\n",
        "        remove_cols.append('ema' + str(period_long))\n",
        "\n",
        "    if not 'ema' + str(period_short) in data.columns:\n",
        "        data = ema(data, period_short)\n",
        "        remove_cols.append('ema' + str(period_short))\n",
        "\n",
        "    data['macd_val'] = data['ema' + str(period_short)] - data['ema' + str(period_long)]\n",
        "    data['macd_signal_line'] = data['macd_val'].ewm(ignore_na=False, min_periods=0, com=period_signal, adjust=True).mean()\n",
        "\n",
        "    data = data.drop(remove_cols, axis=1)\n",
        "        \n",
        "    return data\n",
        "df= macd(df)\n",
        "def acc_dist(data, trend_periods=21, open_col='open', high_col='high', low_col='low', close_col='adj close', vol_col='volume'):\n",
        "    for index, row in data.iterrows():\n",
        "        if row[high_col] != row[low_col]:\n",
        "            ac = ((row[close_col] - row[low_col]) - (row[high_col] - row[close_col])) / (row[high_col] - row[low_col]) * row[vol_col]\n",
        "        else:\n",
        "            ac = 0\n",
        "        data.set_value(index, 'acc_dist', ac)\n",
        "    data['acc_dist_ema' + str(trend_periods)] = data['acc_dist'].ewm(ignore_na=False, min_periods=0, com=trend_periods, adjust=True).mean()\n",
        "    \n",
        "    return data\n",
        "df= acc_dist(df)\n",
        "def on_balance_volume(data, trend_periods=21, close_col='adj close', vol_col='volume'):\n",
        "    for index, row in data.iterrows():\n",
        "        if index:\n",
        "            last_obv = data.at[index - 1, 'obv']\n",
        "            if row[close_col] > data.at[index - 1, close_col]:\n",
        "                current_obv = last_obv + row[vol_col]\n",
        "            elif row[close_col] < data.at[index - 1, close_col]:\n",
        "                current_obv = last_obv - row[vol_col]\n",
        "            else:\n",
        "                current_obv = last_obv\n",
        "        else:\n",
        "            last_obv = 0\n",
        "            current_obv = row[vol_col]\n",
        "\n",
        "        data.set_value(index, 'obv', current_obv)\n",
        "\n",
        "    data['obv_ema' + str(trend_periods)] = data['obv'].ewm(ignore_na=False, min_periods=0, com=trend_periods, adjust=True).mean()\n",
        "    \n",
        "    return data\n",
        "df= on_balance_volume(df)\n",
        "def price_volume_trend(data, trend_periods=21, close_col='adj close', vol_col='volume'):\n",
        "    for index, row in data.iterrows():\n",
        "        if index > 0:\n",
        "            last_val = data.at[index - 1, 'pvt']\n",
        "            last_close = data.at[index - 1, close_col]\n",
        "            today_close = row[close_col]\n",
        "            today_vol = row[vol_col]\n",
        "            current_val = last_val + (today_vol * (today_close - last_close) / last_close)\n",
        "        else:\n",
        "            current_val = row[vol_col]\n",
        "\n",
        "        data.set_value(index, 'pvt', current_val)\n",
        "\n",
        "    data['pvt_ema' + str(trend_periods)] = data['pvt'].ewm(ignore_na=False, min_periods=0, com=trend_periods, adjust=True).mean()\n",
        "        \n",
        "    return data\n",
        "df= price_volume_trend(df)\n",
        "def average_true_range(data, trend_periods=14, open_col='open', high_col='high', low_col='low', close_col='adj close', drop_tr = True):\n",
        "    for index, row in data.iterrows():\n",
        "        prices = [row[high_col], row[low_col], row[close_col], row[open_col]]\n",
        "        if index > 0:\n",
        "            val1 = np.amax(prices) - np.amin(prices)\n",
        "            val2 = abs(np.amax(prices) - data.at[index - 1, close_col])\n",
        "            val3 = abs(np.amin(prices) - data.at[index - 1, close_col])\n",
        "            true_range = np.amax([val1, val2, val3])\n",
        "\n",
        "        else:\n",
        "            true_range = np.amax(prices) - np.amin(prices)\n",
        "\n",
        "        data.set_value(index, 'true_range', true_range)\n",
        "    data['atr'] = data['true_range'].ewm(ignore_na=False, min_periods=0, com=trend_periods, adjust=True).mean()\n",
        "    if drop_tr:\n",
        "        data = data.drop(['true_range'], axis=1)\n",
        "        \n",
        "    return data\n",
        "df= average_true_range(df)\n",
        "def bollinger_bands(data, trend_periods=20, close_col='adj close'):\n",
        "\n",
        "    data['bol_bands_middle'] = data[close_col].ewm(ignore_na=False, min_periods=0, com=trend_periods, adjust=True).mean()\n",
        "    for index, row in data.iterrows():\n",
        "\n",
        "        s = data[close_col].iloc[index - trend_periods: index]\n",
        "        sums = 0\n",
        "        middle_band = data.at[index, 'bol_bands_middle']\n",
        "        for e in s:\n",
        "            sums += np.square(e - middle_band)\n",
        "\n",
        "        std = np.sqrt(sums / trend_periods)\n",
        "        d = 2\n",
        "        upper_band = middle_band + (d * std)\n",
        "        lower_band = middle_band - (d * std)\n",
        "\n",
        "        data.set_value(index, 'bol_bands_upper', upper_band)\n",
        "        data.set_value(index, 'bol_bands_lower', lower_band)\n",
        "\n",
        "    return data\n",
        "df= bollinger_bands(df)\n",
        "def chaikin_oscillator(data, periods_short=3, periods_long=10, high_col='high',\n",
        "                       low_col='low', close_col='adj close', vol_col='volume'):\n",
        "    ac = pd.Series([])\n",
        "    val_last = 0\n",
        "    for index, row in data.iterrows():\n",
        "        if row[high_col] != row[low_col]:\n",
        "            val = val_last + ((row[close_col] - row[low_col]) - (row[high_col] - row[close_col])) / (row[high_col] - row[low_col]) * row[vol_col]\n",
        "        else:\n",
        "            val = val_last\n",
        "        ac.set_value(index, val)\n",
        "    val_last = val\n",
        "    ema_long = ac.ewm(ignore_na=False, min_periods=0, com=periods_long, adjust=True).mean()\n",
        "    ema_short = ac.ewm(ignore_na=False, min_periods=0, com=periods_short, adjust=True).mean()\n",
        "    data['ch_osc'] = ema_short - ema_long\n",
        "\n",
        "    return data\n",
        "df= chaikin_oscillator(df)\n",
        "def typical_price(data, high_col = 'high', low_col = 'low', close_col = 'adj close'):\n",
        "    \n",
        "    data['typical_price'] = (data[high_col] + data[low_col] + data[close_col]) / 3\n",
        "\n",
        "    return data\n",
        "df= typical_price(df)\n",
        "def ease_of_movement(data, period=14, high_col='high', low_col='low', vol_col='volume'):\n",
        "    for index, row in data.iterrows():\n",
        "        if index > 0:\n",
        "            midpoint_move = (row[high_col] + row[low_col]) / 2 - (data.at[index - 1, high_col] + data.at[index - 1, low_col]) / 2\n",
        "        else:\n",
        "            midpoint_move = 0\n",
        "        \n",
        "        diff = row[high_col] - row[low_col]\n",
        "\n",
        "        if diff == 0:\n",
        "            #this is to avoid division by zero below\n",
        "            diff = 0.000000001\n",
        "            \n",
        "        vol = row[vol_col]\n",
        "        if vol == 0:\n",
        "            vol = 1\n",
        "        box_ratio = (vol / 100000000) / (diff)\n",
        "        emv = midpoint_move / box_ratio\n",
        "        \n",
        "        data.set_value(index, 'emv', emv)\n",
        "        \n",
        "    data['emv_ema_'+str(period)] = data['emv'].ewm(ignore_na=False, min_periods=0, com=period, adjust=True).mean()\n",
        "        \n",
        "    return data\n",
        "df= ease_of_movement(df)\n",
        "def mass_index(data, period=25, ema_period=9, high_col='high', low_col='low'):\n",
        "    high_low = data[high_col] - data[low_col] + 0.000001\t#this is to avoid division by zero below\n",
        "    ema = high_low.ewm(ignore_na=False, min_periods=0, com=ema_period, adjust=True).mean()\n",
        "    ema_ema = ema.ewm(ignore_na=False, min_periods=0, com=ema_period, adjust=True).mean()\n",
        "    div = ema / ema_ema\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        if index >= period:\n",
        "            val = div[index-25:index].sum()\n",
        "        else:\n",
        "            val = 0\n",
        "        data.set_value(index, 'mass_index', val)\n",
        "         \n",
        "    return data\n",
        "df= mass_index(df)\n",
        "def directional_movement_index(data, periods=14, high_col='high', low_col='low'):\n",
        "    remove_tr_col = False\n",
        "    if not 'true_range' in data.columns:\n",
        "        data = average_true_range(data, drop_tr = False)\n",
        "        remove_tr_col = True\n",
        "\n",
        "    data['m_plus'] = 0.\n",
        "    data['m_minus'] = 0.\n",
        "    \n",
        "    for i,row in data.iterrows():\n",
        "        if i>0:\n",
        "            data.set_value(i, 'm_plus', row[high_col] - data.at[i-1, high_col])\n",
        "            data.set_value(i, 'm_minus', row[low_col] - data.at[i-1, low_col])\n",
        "    \n",
        "    data['dm_plus'] = 0.\n",
        "    data['dm_minus'] = 0.\n",
        "    \n",
        "    for i,row in data.iterrows():\n",
        "        if row['m_plus'] > row['m_minus'] and row['m_plus'] > 0:\n",
        "            data.set_value(i, 'dm_plus', row['m_plus'])\n",
        "            \n",
        "        if row['m_minus'] > row['m_plus'] and row['m_minus'] > 0:\n",
        "            data.set_value(i, 'dm_minus', row['m_minus'])\n",
        "    \n",
        "    data['di_plus'] = (data['dm_plus'] / data['true_range']).ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean()\n",
        "    data['di_minus'] = (data['dm_minus'] / data['true_range']).ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean()\n",
        "    \n",
        "    data['dxi'] = np.abs(data['di_plus'] - data['di_minus']) / (data['di_plus'] + data['di_minus'])\n",
        "    data.set_value(0, 'dxi',1.)\n",
        "    data['adx'] = data['dxi'].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean()\n",
        "    data = data.drop(['m_plus', 'm_minus', 'dm_plus', 'dm_minus'], axis=1)\n",
        "    if remove_tr_col:\n",
        "        data = data.drop(['true_range'], axis=1)\n",
        "         \n",
        "    return data\n",
        "df= directional_movement_index(df)\n",
        "\n",
        "def money_flow_index(data, periods=14, vol_col='volume'):\n",
        "    remove_tp_col = False\n",
        "    if not 'typical_price' in data.columns:\n",
        "        data = typical_price(data)\n",
        "        remove_tp_col = True\n",
        "    \n",
        "    data['money_flow'] = data['typical_price'] * data[vol_col]\n",
        "    data['money_ratio'] = 0.\n",
        "    data['money_flow_index'] = 0.\n",
        "    data['money_flow_positive'] = 0.\n",
        "    data['money_flow_negative'] = 0.\n",
        "    \n",
        "    for index,row in data.iterrows():\n",
        "        if index > 0:\n",
        "            if row['typical_price'] < data.at[index-1, 'typical_price']:\n",
        "                data.set_value(index, 'money_flow_positive', row['money_flow'])\n",
        "            else:\n",
        "                data.set_value(index, 'money_flow_negative', row['money_flow'])\n",
        "    \n",
        "        if index >= periods:\n",
        "            period_slice = data['money_flow'][index-periods:index]\n",
        "            positive_sum = data['money_flow_positive'][index-periods:index].sum()\n",
        "            negative_sum = data['money_flow_negative'][index-periods:index].sum()\n",
        "\n",
        "            if negative_sum == 0.:\n",
        "                #this is to avoid division by zero below\n",
        "                negative_sum = 0.00001\n",
        "            m_r = positive_sum / negative_sum\n",
        "\n",
        "            mfi = 1-(1 / (1 + m_r))\n",
        "\n",
        "            data.set_value(index, 'money_ratio', m_r)\n",
        "            data.set_value(index, 'money_flow_index', mfi)\n",
        "          \n",
        "    data = data.drop(['money_flow', 'money_ratio', 'money_flow_positive', 'money_flow_negative'], axis=1)\n",
        "    \n",
        "    if remove_tp_col:\n",
        "        data = data.drop(['typical_price'], axis=1)\n",
        "\n",
        "    return data\n",
        "df= money_flow_index(df)\n",
        "\n",
        "def negative_volume_index(data, periods=255, close_col='adj close', vol_col='volume'):\n",
        "    data['nvi'] = 0.\n",
        "    \n",
        "    for index,row in data.iterrows():\n",
        "        if index > 0:\n",
        "            prev_nvi = data.at[index-1, 'nvi']\n",
        "            prev_close = data.at[index-1, close_col]\n",
        "            if row[vol_col] < data.at[index-1, vol_col]:\n",
        "                nvi = prev_nvi + (row[close_col] - prev_close / prev_close * prev_nvi)\n",
        "            else: \n",
        "                nvi = prev_nvi\n",
        "        else:\n",
        "            nvi = 1000\n",
        "        data.set_value(index, 'nvi', nvi)\n",
        "    data['nvi_ema'] = data['nvi'].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean()\n",
        "    \n",
        "    return data\n",
        "df= negative_volume_index(df)\n",
        "def positive_volume_index(data, periods=255, close_col='adj close', vol_col='volume'):\n",
        "    data['pvi'] = 0.\n",
        "    \n",
        "    for index,row in data.iterrows():\n",
        "        if index > 0:\n",
        "            prev_pvi = data.at[index-1, 'pvi']\n",
        "            prev_close = data.at[index-1, close_col]\n",
        "            if row[vol_col] > data.at[index-1, vol_col]:\n",
        "                pvi = prev_pvi + (row[close_col] - prev_close / prev_close * prev_pvi)\n",
        "            else: \n",
        "                pvi = prev_pvi\n",
        "        else:\n",
        "            pvi = 1000\n",
        "        data.set_value(index, 'pvi', pvi)\n",
        "    data['pvi_ema'] = data['pvi'].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean()\n",
        "\n",
        "    return data\n",
        "df= positive_volume_index(df)\n",
        "def momentum(data, periods=14, close_col='adj close'):\n",
        "    data['momentum'] = 0.\n",
        "    \n",
        "    for index,row in data.iterrows():\n",
        "        if index >= periods:\n",
        "            prev_close = data.at[index-periods, close_col]\n",
        "            val_perc = (row[close_col] - prev_close)/prev_close\n",
        "\n",
        "            data.set_value(index, 'momentum', val_perc)\n",
        "\n",
        "    return data\n",
        "df= momentum(df)\n",
        "def rsi(data, periods=14, close_col='adj close'):\n",
        "    data['rsi_u'] = 0.\n",
        "    data['rsi_d'] = 0.\n",
        "    data['rsi'] = 0.\n",
        "    \n",
        "    for index,row in data.iterrows():\n",
        "        if index >= periods:\n",
        "            \n",
        "            prev_close = data.at[index-periods, close_col]\n",
        "            if prev_close < row[close_col]:\n",
        "                data.set_value(index, 'rsi_u', row[close_col] - prev_close)\n",
        "            elif prev_close > row[close_col]:\n",
        "                data.set_value(index, 'rsi_d', prev_close - row[close_col])\n",
        "            \n",
        "    data['rsi'] = data['rsi_u'].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean() / (data['rsi_u'].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean() + data['rsi_d'].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean())\n",
        "    \n",
        "    data = data.drop(['rsi_u', 'rsi_d'], axis=1)\n",
        "        \n",
        "    return data\n",
        "df= rsi(df)\n",
        "def chaikin_volatility(data, ema_periods=10, change_periods=10, high_col='high', low_col='low', close_col='adj close'):\n",
        "    data['ch_vol_hl'] = data[high_col] - data[low_col]\n",
        "    data['ch_vol_ema'] = data['ch_vol_hl'].ewm(ignore_na=False, min_periods=0, com=ema_periods, adjust=True).mean()\n",
        "    data['chaikin_volatility'] = 0.\n",
        "    \n",
        "    for index,row in data.iterrows():\n",
        "        if index >= change_periods:\n",
        "            \n",
        "            prev_value = data.at[index-change_periods, 'ch_vol_ema']\n",
        "            if prev_value == 0:\n",
        "                #this is to avoid division by zero below\n",
        "                prev_value = 0.0001\n",
        "            data.set_value(index, 'chaikin_volatility', ((row['ch_vol_ema'] - prev_value)/prev_value))\n",
        "            \n",
        "    data = data.drop(['ch_vol_hl', 'ch_vol_ema'], axis=1)\n",
        "        \n",
        "    return data\n",
        "df= chaikin_volatility(df)\n",
        "def williams_ad(data, high_col='high', low_col='low', close_col='adj close'):\n",
        "    data['williams_ad'] = 0.\n",
        "    \n",
        "    for index,row in data.iterrows():\n",
        "        if index > 0:\n",
        "            prev_value = data.at[index-1, 'williams_ad']\n",
        "            prev_close = data.at[index-1, close_col]\n",
        "            if row[close_col] > prev_close:\n",
        "                ad = row[close_col] - min(prev_close, row[low_col])\n",
        "            elif row[close_col] < prev_close:\n",
        "                ad = row[close_col] - max(prev_close, row[high_col])\n",
        "            else:\n",
        "                ad = 0.\n",
        "                                                                                                        \n",
        "            data.set_value(index, 'williams_ad', (ad+prev_value))\n",
        "        \n",
        "    return data\n",
        "df= williams_ad(df)\n",
        "def williams_r(data, periods=14, high_col='high', low_col='low', close_col='adj close'):\n",
        "    data['williams_r'] = 0.\n",
        "    \n",
        "    for index,row in data.iterrows():\n",
        "        if index > periods:\n",
        "            data.set_value(index, 'williams_r', ((max(data[high_col][index-periods:index]) - row[close_col]) / \n",
        "                                                 (max(data[high_col][index-periods:index]) - min(data[low_col][index-periods:index]))))\n",
        "        \n",
        "    return data\n",
        "df= williams_r(df)\n",
        "def trix(data, periods=14, signal_periods=9, close_col='adj close'):\n",
        "    data['trix'] = data[close_col].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean()\n",
        "    data['trix'] = data['trix'].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean()\n",
        "    data['trix'] = data['trix'].ewm(ignore_na=False, min_periods=0, com=periods, adjust=True).mean()\n",
        "    data['trix_signal'] = data['trix'].ewm(ignore_na=False, min_periods=0, com=signal_periods, adjust=True).mean()\n",
        "        \n",
        "    return data\n",
        "df= trix(df)\n",
        "def ultimate_oscillator(data, period_1=7,period_2=14, period_3=28, high_col='high', low_col='low', close_col='adj close'):\n",
        "    data['ultimate_oscillator'] = 0.\n",
        "    data['uo_bp'] = 0.\n",
        "    data['uo_tr'] = 0.\n",
        "    data['uo_avg_1'] = 0.\n",
        "    data['uo_avg_2'] = 0.\n",
        "    data['uo_avg_3'] = 0.\n",
        "\n",
        "    for index,row in data.iterrows():\n",
        "        if index > 0:\n",
        "                           \n",
        "            bp = row[close_col] - min(row[low_col], data.at[index-1, close_col])\n",
        "            tr = max(row[high_col], data.at[index-1, close_col]) - min(row[low_col], data.at[index-1, close_col])\n",
        "            \n",
        "            data.set_value(index, 'uo_bp', bp)\n",
        "            data.set_value(index, 'uo_tr', tr)\n",
        "            if index >= period_1:\n",
        "                uo_avg_1 = sum(data['uo_bp'][index-period_1:index]) / sum(data['uo_tr'][index-period_1:index])\n",
        "                data.set_value(index, 'uo_avg_1', uo_avg_1)\n",
        "            if index >= period_2:\n",
        "                uo_avg_2 = sum(data['uo_bp'][index-period_2:index]) / sum(data['uo_tr'][index-period_2:index])\n",
        "                data.set_value(index, 'uo_avg_2', uo_avg_2)\n",
        "            if index >= period_3:\n",
        "                uo_avg_3 = sum(data['uo_bp'][index-period_3:index]) / sum(data['uo_tr'][index-period_3:index])\n",
        "                data.set_value(index, 'uo_avg_3', uo_avg_3)\n",
        "                uo = (4 * uo_avg_1 + 2 * uo_avg_2 + uo_avg_3) / 7\n",
        "                data.set_value(index, 'ultimate_oscillator', uo)\n",
        "\n",
        "    data = data.drop(['uo_bp', 'uo_tr', 'uo_avg_1', 'uo_avg_2', 'uo_avg_3'], axis=1)\n",
        "        \n",
        "    return data\n",
        "df= ultimate_oscillator(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfeiXSF89p49",
        "colab_type": "code",
        "outputId": "41e36686-c968-4ae9-92aa-d7edb06b9e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "df[\"close\"] = df['adj close'] # Moving close to the last column\n",
        "df.drop(['adj close'], 1, inplace=True) # Moving close to the last column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>ema0.5</th>\n",
              "      <th>macd_val</th>\n",
              "      <th>macd_signal_line</th>\n",
              "      <th>acc_dist</th>\n",
              "      <th>acc_dist_ema21</th>\n",
              "      <th>obv</th>\n",
              "      <th>obv_ema21</th>\n",
              "      <th>pvt</th>\n",
              "      <th>pvt_ema21</th>\n",
              "      <th>atr</th>\n",
              "      <th>bol_bands_middle</th>\n",
              "      <th>bol_bands_upper</th>\n",
              "      <th>bol_bands_lower</th>\n",
              "      <th>ch_osc</th>\n",
              "      <th>typical_price</th>\n",
              "      <th>emv</th>\n",
              "      <th>emv_ema_14</th>\n",
              "      <th>mass_index</th>\n",
              "      <th>di_plus</th>\n",
              "      <th>di_minus</th>\n",
              "      <th>dxi</th>\n",
              "      <th>adx</th>\n",
              "      <th>money_flow_index</th>\n",
              "      <th>nvi</th>\n",
              "      <th>nvi_ema</th>\n",
              "      <th>pvi</th>\n",
              "      <th>pvi_ema</th>\n",
              "      <th>momentum</th>\n",
              "      <th>rsi</th>\n",
              "      <th>chaikin_volatility</th>\n",
              "      <th>williams_ad</th>\n",
              "      <th>williams_r</th>\n",
              "      <th>trix</th>\n",
              "      <th>trix_signal</th>\n",
              "      <th>ultimate_oscillator</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>1455.219971</td>\n",
              "      <td>1397.430054</td>\n",
              "      <td>1455.219971</td>\n",
              "      <td>1009000000</td>\n",
              "      <td>1399.420044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-9.395104e+08</td>\n",
              "      <td>-9.395104e+08</td>\n",
              "      <td>1.009000e+09</td>\n",
              "      <td>1.009000e+09</td>\n",
              "      <td>1.009000e+09</td>\n",
              "      <td>1.009000e+09</td>\n",
              "      <td>57.789917</td>\n",
              "      <td>1399.420044</td>\n",
              "      <td>1399.420044</td>\n",
              "      <td>1399.420044</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1417.356689</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1399.420044</td>\n",
              "      <td>1399.420044</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1399.420044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>1413.270020</td>\n",
              "      <td>1377.680054</td>\n",
              "      <td>1399.420044</td>\n",
              "      <td>1085500000</td>\n",
              "      <td>1401.437500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.047341e+08</td>\n",
              "      <td>-2.517574e+08</td>\n",
              "      <td>2.094500e+09</td>\n",
              "      <td>1.564372e+09</td>\n",
              "      <td>1.011087e+09</td>\n",
              "      <td>1.010068e+09</td>\n",
              "      <td>46.307184</td>\n",
              "      <td>1400.797819</td>\n",
              "      <td>1400.797819</td>\n",
              "      <td>1400.797819</td>\n",
              "      <td>6.401164e+07</td>\n",
              "      <td>1397.686686</td>\n",
              "      <td>-101.146898</td>\n",
              "      <td>-52.317361</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1402.109985</td>\n",
              "      <td>1201.448447</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.429932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1399.792284</td>\n",
              "      <td>1399.615960</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1402.109985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-06</td>\n",
              "      <td>1411.900024</td>\n",
              "      <td>1392.099976</td>\n",
              "      <td>1402.109985</td>\n",
              "      <td>1092300000</td>\n",
              "      <td>1402.830735</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.599776e+08</td>\n",
              "      <td>-1.080806e+08</td>\n",
              "      <td>3.186800e+09</td>\n",
              "      <td>2.130526e+09</td>\n",
              "      <td>1.012130e+09</td>\n",
              "      <td>1.010787e+09</td>\n",
              "      <td>36.855353</td>\n",
              "      <td>1401.725329</td>\n",
              "      <td>1401.725329</td>\n",
              "      <td>1401.725329</td>\n",
              "      <td>6.277004e+07</td>\n",
              "      <td>1402.483317</td>\n",
              "      <td>11.827757</td>\n",
              "      <td>-29.444696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259687</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1403.449951</td>\n",
              "      <td>1269.045991</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.779907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1400.121196</td>\n",
              "      <td>1399.802394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1403.449951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-07</td>\n",
              "      <td>1441.469971</td>\n",
              "      <td>1400.729980</td>\n",
              "      <td>1403.449951</td>\n",
              "      <td>1225200000</td>\n",
              "      <td>1428.912219</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.225200e+09</td>\n",
              "      <td>2.488464e+08</td>\n",
              "      <td>4.412000e+09</td>\n",
              "      <td>2.741290e+09</td>\n",
              "      <td>1.045322e+09</td>\n",
              "      <td>1.020032e+09</td>\n",
              "      <td>37.929204</td>\n",
              "      <td>1412.400052</td>\n",
              "      <td>1412.400052</td>\n",
              "      <td>1412.400052</td>\n",
              "      <td>1.436807e+08</td>\n",
              "      <td>1427.889974</td>\n",
              "      <td>63.510677</td>\n",
              "      <td>-3.748539</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200643</td>\n",
              "      <td>0.187900</td>\n",
              "      <td>0.032796</td>\n",
              "      <td>0.647825</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1441.469971</td>\n",
              "      <td>1312.405384</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>76.519897</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1401.203553</td>\n",
              "      <td>1400.209826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1441.469971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-10</td>\n",
              "      <td>1464.359985</td>\n",
              "      <td>1441.469971</td>\n",
              "      <td>1441.469971</td>\n",
              "      <td>1064800000</td>\n",
              "      <td>1448.116420</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.358744e+08</td>\n",
              "      <td>2.898106e+08</td>\n",
              "      <td>5.476800e+09</td>\n",
              "      <td>3.340440e+09</td>\n",
              "      <td>1.057237e+09</td>\n",
              "      <td>1.028181e+09</td>\n",
              "      <td>34.492709</td>\n",
              "      <td>1422.342950</td>\n",
              "      <td>1422.342950</td>\n",
              "      <td>1422.342950</td>\n",
              "      <td>1.097177e+08</td>\n",
              "      <td>1454.476644</td>\n",
              "      <td>68.392738</td>\n",
              "      <td>12.735937</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.154795</td>\n",
              "      <td>0.551657</td>\n",
              "      <td>0.561767</td>\n",
              "      <td>0.623673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1457.599976</td>\n",
              "      <td>1092.237793</td>\n",
              "      <td>1441.469971</td>\n",
              "      <td>1338.420754</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.649902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1402.840231</td>\n",
              "      <td>1400.852156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1457.599976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date         high  ...  ultimate_oscillator        close\n",
              "0 2000-01-04  1455.219971  ...                  0.0  1399.420044\n",
              "1 2000-01-05  1413.270020  ...                  0.0  1402.109985\n",
              "2 2000-01-06  1411.900024  ...                  0.0  1403.449951\n",
              "3 2000-01-07  1441.469971  ...                  0.0  1441.469971\n",
              "4 2000-01-10  1464.359985  ...                  0.0  1457.599976\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzVIXybt9_pt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.set_index('Date', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_ZgXhUH6yOa",
        "colab_type": "text"
      },
      "source": [
        "NORMALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQF8kXFD-Yvr",
        "colab_type": "code",
        "outputId": "2761bace-0539-4a8e-8f52-8362c9144773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "def normalize(df):\n",
        "    df = min_max_scaler.fit_transform(df.values.reshape(-1,1))\n",
        "    return df\n",
        "for i in df.columns:\n",
        "    df[i] = normalize(df[i])\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>ema0.5</th>\n",
              "      <th>macd_val</th>\n",
              "      <th>macd_signal_line</th>\n",
              "      <th>acc_dist</th>\n",
              "      <th>acc_dist_ema21</th>\n",
              "      <th>obv</th>\n",
              "      <th>obv_ema21</th>\n",
              "      <th>pvt</th>\n",
              "      <th>pvt_ema21</th>\n",
              "      <th>atr</th>\n",
              "      <th>bol_bands_middle</th>\n",
              "      <th>bol_bands_upper</th>\n",
              "      <th>bol_bands_lower</th>\n",
              "      <th>ch_osc</th>\n",
              "      <th>typical_price</th>\n",
              "      <th>emv</th>\n",
              "      <th>emv_ema_14</th>\n",
              "      <th>mass_index</th>\n",
              "      <th>di_plus</th>\n",
              "      <th>di_minus</th>\n",
              "      <th>dxi</th>\n",
              "      <th>adx</th>\n",
              "      <th>money_flow_index</th>\n",
              "      <th>nvi</th>\n",
              "      <th>nvi_ema</th>\n",
              "      <th>pvi</th>\n",
              "      <th>pvi_ema</th>\n",
              "      <th>momentum</th>\n",
              "      <th>rsi</th>\n",
              "      <th>chaikin_volatility</th>\n",
              "      <th>williams_ad</th>\n",
              "      <th>williams_r</th>\n",
              "      <th>trix</th>\n",
              "      <th>trix_signal</th>\n",
              "      <th>ultimate_oscillator</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4394.000000</td>\n",
              "      <td>4394.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4418.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4405.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "      <td>4419.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.403274</td>\n",
              "      <td>0.404998</td>\n",
              "      <td>0.404169</td>\n",
              "      <td>0.241130</td>\n",
              "      <td>0.405386</td>\n",
              "      <td>0.739294</td>\n",
              "      <td>0.734642</td>\n",
              "      <td>0.520420</td>\n",
              "      <td>0.514665</td>\n",
              "      <td>0.418099</td>\n",
              "      <td>0.416726</td>\n",
              "      <td>0.699303</td>\n",
              "      <td>0.634115</td>\n",
              "      <td>0.180836</td>\n",
              "      <td>0.375316</td>\n",
              "      <td>0.367482</td>\n",
              "      <td>0.396458</td>\n",
              "      <td>0.521615</td>\n",
              "      <td>0.404363</td>\n",
              "      <td>0.715604</td>\n",
              "      <td>0.684841</td>\n",
              "      <td>0.758359</td>\n",
              "      <td>0.496996</td>\n",
              "      <td>0.475165</td>\n",
              "      <td>0.371485</td>\n",
              "      <td>0.318662</td>\n",
              "      <td>0.499557</td>\n",
              "      <td>0.406504</td>\n",
              "      <td>0.301715</td>\n",
              "      <td>0.393494</td>\n",
              "      <td>0.301262</td>\n",
              "      <td>0.561995</td>\n",
              "      <td>0.591328</td>\n",
              "      <td>0.304714</td>\n",
              "      <td>0.386182</td>\n",
              "      <td>0.385836</td>\n",
              "      <td>0.370108</td>\n",
              "      <td>0.369504</td>\n",
              "      <td>0.618509</td>\n",
              "      <td>0.406293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.221863</td>\n",
              "      <td>0.219730</td>\n",
              "      <td>0.220175</td>\n",
              "      <td>0.139230</td>\n",
              "      <td>0.220903</td>\n",
              "      <td>0.148258</td>\n",
              "      <td>0.158314</td>\n",
              "      <td>0.124555</td>\n",
              "      <td>0.131595</td>\n",
              "      <td>0.347617</td>\n",
              "      <td>0.352745</td>\n",
              "      <td>0.146924</td>\n",
              "      <td>0.178003</td>\n",
              "      <td>0.140182</td>\n",
              "      <td>0.234470</td>\n",
              "      <td>0.240006</td>\n",
              "      <td>0.224349</td>\n",
              "      <td>0.100449</td>\n",
              "      <td>0.221030</td>\n",
              "      <td>0.024407</td>\n",
              "      <td>0.048282</td>\n",
              "      <td>0.081965</td>\n",
              "      <td>0.152517</td>\n",
              "      <td>0.133659</td>\n",
              "      <td>0.154087</td>\n",
              "      <td>0.113530</td>\n",
              "      <td>0.161223</td>\n",
              "      <td>0.220954</td>\n",
              "      <td>0.255992</td>\n",
              "      <td>0.224595</td>\n",
              "      <td>0.255620</td>\n",
              "      <td>0.078181</td>\n",
              "      <td>0.310576</td>\n",
              "      <td>0.090284</td>\n",
              "      <td>0.270085</td>\n",
              "      <td>0.136920</td>\n",
              "      <td>0.237813</td>\n",
              "      <td>0.238408</td>\n",
              "      <td>0.133415</td>\n",
              "      <td>0.220542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.248020</td>\n",
              "      <td>0.252396</td>\n",
              "      <td>0.250211</td>\n",
              "      <td>0.107150</td>\n",
              "      <td>0.251782</td>\n",
              "      <td>0.665612</td>\n",
              "      <td>0.659903</td>\n",
              "      <td>0.444158</td>\n",
              "      <td>0.422268</td>\n",
              "      <td>0.075626</td>\n",
              "      <td>0.071920</td>\n",
              "      <td>0.623999</td>\n",
              "      <td>0.538627</td>\n",
              "      <td>0.085312</td>\n",
              "      <td>0.207555</td>\n",
              "      <td>0.190072</td>\n",
              "      <td>0.244049</td>\n",
              "      <td>0.470460</td>\n",
              "      <td>0.250381</td>\n",
              "      <td>0.712403</td>\n",
              "      <td>0.680159</td>\n",
              "      <td>0.722412</td>\n",
              "      <td>0.385944</td>\n",
              "      <td>0.377263</td>\n",
              "      <td>0.273738</td>\n",
              "      <td>0.249671</td>\n",
              "      <td>0.386671</td>\n",
              "      <td>0.253606</td>\n",
              "      <td>0.106116</td>\n",
              "      <td>0.235391</td>\n",
              "      <td>0.105073</td>\n",
              "      <td>0.524914</td>\n",
              "      <td>0.313720</td>\n",
              "      <td>0.248230</td>\n",
              "      <td>0.175237</td>\n",
              "      <td>0.271026</td>\n",
              "      <td>0.199904</td>\n",
              "      <td>0.198339</td>\n",
              "      <td>0.530823</td>\n",
              "      <td>0.252032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.346456</td>\n",
              "      <td>0.349733</td>\n",
              "      <td>0.348415</td>\n",
              "      <td>0.247441</td>\n",
              "      <td>0.349895</td>\n",
              "      <td>0.772081</td>\n",
              "      <td>0.771760</td>\n",
              "      <td>0.524861</td>\n",
              "      <td>0.479691</td>\n",
              "      <td>0.299149</td>\n",
              "      <td>0.296371</td>\n",
              "      <td>0.667114</td>\n",
              "      <td>0.592613</td>\n",
              "      <td>0.146567</td>\n",
              "      <td>0.314631</td>\n",
              "      <td>0.306297</td>\n",
              "      <td>0.345163</td>\n",
              "      <td>0.523041</td>\n",
              "      <td>0.348517</td>\n",
              "      <td>0.716938</td>\n",
              "      <td>0.696650</td>\n",
              "      <td>0.757991</td>\n",
              "      <td>0.490786</td>\n",
              "      <td>0.467010</td>\n",
              "      <td>0.379287</td>\n",
              "      <td>0.324353</td>\n",
              "      <td>0.496797</td>\n",
              "      <td>0.350630</td>\n",
              "      <td>0.224633</td>\n",
              "      <td>0.336991</td>\n",
              "      <td>0.224020</td>\n",
              "      <td>0.569207</td>\n",
              "      <td>0.670781</td>\n",
              "      <td>0.291342</td>\n",
              "      <td>0.298802</td>\n",
              "      <td>0.363169</td>\n",
              "      <td>0.309640</td>\n",
              "      <td>0.309568</td>\n",
              "      <td>0.623328</td>\n",
              "      <td>0.350336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.482021</td>\n",
              "      <td>0.486257</td>\n",
              "      <td>0.484142</td>\n",
              "      <td>0.324323</td>\n",
              "      <td>0.485683</td>\n",
              "      <td>0.845100</td>\n",
              "      <td>0.847433</td>\n",
              "      <td>0.600374</td>\n",
              "      <td>0.596246</td>\n",
              "      <td>0.767000</td>\n",
              "      <td>0.756019</td>\n",
              "      <td>0.790972</td>\n",
              "      <td>0.737724</td>\n",
              "      <td>0.248479</td>\n",
              "      <td>0.445692</td>\n",
              "      <td>0.440042</td>\n",
              "      <td>0.471435</td>\n",
              "      <td>0.575592</td>\n",
              "      <td>0.484812</td>\n",
              "      <td>0.720701</td>\n",
              "      <td>0.704630</td>\n",
              "      <td>0.796050</td>\n",
              "      <td>0.600294</td>\n",
              "      <td>0.562696</td>\n",
              "      <td>0.474224</td>\n",
              "      <td>0.394565</td>\n",
              "      <td>0.611539</td>\n",
              "      <td>0.487020</td>\n",
              "      <td>0.361851</td>\n",
              "      <td>0.475451</td>\n",
              "      <td>0.362913</td>\n",
              "      <td>0.606836</td>\n",
              "      <td>0.874374</td>\n",
              "      <td>0.341772</td>\n",
              "      <td>0.594931</td>\n",
              "      <td>0.490447</td>\n",
              "      <td>0.437523</td>\n",
              "      <td>0.436694</td>\n",
              "      <td>0.710222</td>\n",
              "      <td>0.486293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              high          low  ...  ultimate_oscillator        close\n",
              "count  4419.000000  4419.000000  ...          4419.000000  4419.000000\n",
              "mean      0.403274     0.404998  ...             0.618509     0.406293\n",
              "std       0.221863     0.219730  ...             0.133415     0.220542\n",
              "min       0.000000     0.000000  ...             0.000000     0.000000\n",
              "25%       0.248020     0.252396  ...             0.530823     0.252032\n",
              "50%       0.346456     0.349733  ...             0.623328     0.350336\n",
              "75%       0.482021     0.486257  ...             0.710222     0.486293\n",
              "max       1.000000     1.000000  ...             1.000000     1.000000\n",
              "\n",
              "[8 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mywjtmE9-8ku",
        "colab_type": "code",
        "outputId": "370260c8-ce4a-4f78-dcaa-67a8f2a54162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "df.fillna(0, inplace = True)\n",
        "df.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "high                   0\n",
              "low                    0\n",
              "open                   0\n",
              "volume                 0\n",
              "ema0.5                 0\n",
              "macd_val               0\n",
              "macd_signal_line       0\n",
              "acc_dist               0\n",
              "acc_dist_ema21         0\n",
              "obv                    0\n",
              "obv_ema21              0\n",
              "pvt                    0\n",
              "pvt_ema21              0\n",
              "atr                    0\n",
              "bol_bands_middle       0\n",
              "bol_bands_upper        0\n",
              "bol_bands_lower        0\n",
              "ch_osc                 0\n",
              "typical_price          0\n",
              "emv                    0\n",
              "emv_ema_14             0\n",
              "mass_index             0\n",
              "di_plus                0\n",
              "di_minus               0\n",
              "dxi                    0\n",
              "adx                    0\n",
              "money_flow_index       0\n",
              "nvi                    0\n",
              "nvi_ema                0\n",
              "pvi                    0\n",
              "pvi_ema                0\n",
              "momentum               0\n",
              "rsi                    0\n",
              "chaikin_volatility     0\n",
              "williams_ad            0\n",
              "williams_r             0\n",
              "trix                   0\n",
              "trix_signal            0\n",
              "ultimate_oscillator    0\n",
              "close                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIjrgzwX7BY4",
        "colab_type": "text"
      },
      "source": [
        "TRAIN-TEST SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daFpViJTADpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(stock, seq_len):\n",
        "    amount_of_features = len(stock.columns) # 40\n",
        "    data = stock.as_matrix() \n",
        "    sequence_length = seq_len + 1 # index starting from 0\n",
        "    result = []\n",
        "    \n",
        "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
        "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
        "    \n",
        "    result = np.array(result)\n",
        "    #row = round(0.9 * result.shape[0]) # 90% split\n",
        "    train = result[:2009, :] # 90% date, all features \n",
        "    \n",
        "    x_train = train[:, :-1] \n",
        "    y_train = train[:, -1][:,-1]\n",
        "    \n",
        "    x_test = result[2009:, :-1] \n",
        "    y_test = result[2009:, -1][:,-1]\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
        "\n",
        "    return [x_train, y_train, x_test, y_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6EDWizyADn_",
        "colab_type": "code",
        "outputId": "c94e660d-cc3b-4ba0-9773-f181f282c121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2635
        }
      },
      "source": [
        "window = 22\n",
        "X_train, y_train, X_test, y_test = load_data(df, window)\n",
        "print (X_train[0], y_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.42484497 0.40408157 0.43024594 0.05882167 0.40046559 0.\n",
            "  0.         0.45238574 0.10987121 0.07265371 0.06894202 0.64692154\n",
            "  0.57073523 0.91963442 0.37269686 0.3325853  0.42420864 0.52137316\n",
            "  0.40955105 0.71661081 0.69523139 0.         0.         0.\n",
            "  1.         1.         0.         0.17957584 0.00279597 0.16274813\n",
            "  0.00161676 0.55698682 0.         0.29886197 0.21712922 0.23860201\n",
            "  0.37052198 0.37119453 0.         0.40131571]\n",
            " [0.40139313 0.3931588  0.3993058  0.06571347 0.40158816 0.\n",
            "  0.         0.52551449 0.33306722 0.07381925 0.06955    0.64732128\n",
            "  0.57099056 0.70614355 0.37352733 0.33343146 0.42500303 0.53474197\n",
            "  0.39860255 0.58263754 0.         0.         0.         0.\n",
            "  0.         1.         0.         0.17957584 0.00279597 0.39066806\n",
            "  0.1698297  0.55698682 0.         0.29886197 0.22479715 0.23860201\n",
            "  0.37075393 0.37131785 0.         0.40280905]\n",
            " [0.40062725 0.40113376 0.40079733 0.06632607 0.4023634  0.\n",
            "  0.         0.5121994  0.37969455 0.0749921  0.07016978 0.64752127\n",
            "  0.57116274 0.53041191 0.3740864  0.33400109 0.4255378  0.53448266\n",
            "  0.4012724  0.73227716 0.30394872 0.         0.         0.41623512\n",
            "  1.         1.         0.         0.17957584 0.00279597 0.39142757\n",
            "  0.22627481 0.55698682 0.         0.29886197 0.22835961 0.23860201\n",
            "  0.37095888 0.3714352  0.         0.40355294]\n",
            " [0.41715813 0.4059066  0.40154032 0.07829887 0.41687593 0.\n",
            "  0.         0.57014897 0.49552783 0.07630764 0.0708384  0.65388011\n",
            "  0.57337398 0.55037732 0.38052071 0.34055695 0.43169257 0.55138082\n",
            "  0.41541397 0.80073334 0.64541806 0.         0.74107962 0.30117299\n",
            "  0.03205597 0.61786763 0.         0.17957584 0.00279597 0.41297769\n",
            "  0.26248066 0.55698682 0.         0.29886197 0.24114685 0.23860201\n",
            "  0.37163333 0.37169167 0.         0.42465992]\n",
            " [0.42995464 0.42843791 0.42262179 0.06384863 0.42756173 0.\n",
            "  0.         0.52720857 0.5088219  0.07745096 0.0714943  0.65616282\n",
            "  0.57532302 0.48648484 0.3865139  0.34666337 0.43742539 0.54428767\n",
            "  0.43021235 0.80719983 0.86447584 0.         0.57174093 0.88421529\n",
            "  0.56143202 0.59166211 0.         0.43361457 0.07952058 0.41297769\n",
            "  0.28420394 0.55698682 0.         0.29886197 0.24620964 0.23860201\n",
            "  0.37265319 0.37209599 0.         0.43361457]\n",
            " [0.42676812 0.42453894 0.43156561 0.05927212 0.4240119  0.\n",
            "  0.         0.46717628 0.45083174 0.07636219 0.07172362 0.65362524\n",
            "  0.57602877 0.44899448 0.38834805 0.34853217 0.43917985 0.51759459\n",
            "  0.42431419 0.69642546 0.79136079 0.         0.45929448 0.71031332\n",
            "  0.56143202 0.57613361 0.         0.42304447 0.12800416 0.41297769\n",
            "  0.29868594 0.55698682 0.         0.29886197 0.23990077 0.23860201\n",
            "  0.37375658 0.37260095 0.         0.42304447]\n",
            " [0.41778985 0.42047949 0.42100829 0.05572262 0.42049114 0.\n",
            "  0.         0.48580069 0.42766985 0.07531572 0.07171257 0.65280624\n",
            "  0.57636457 0.39412523 0.38902904 0.34922601 0.43983124 0.50931032\n",
            "  0.41880187 0.69193223 0.73153715 0.         0.37935588 0.58668577\n",
            "  0.56143202 0.56588147 0.         0.41954141 0.1618761  0.41297769\n",
            "  0.30903007 0.55698682 0.         0.29886197 0.23665218 0.23860201\n",
            "  0.37482947 0.37316542 0.         0.41954141]\n",
            " [0.42427474 0.42333879 0.41750947 0.06074957 0.42578571 0.\n",
            "  0.         0.536466   0.45455134 0.0764221  0.0718693  0.65520861\n",
            "  0.57705449 0.37198952 0.39108649 0.35132233 0.44179931 0.52550768\n",
            "  0.42514722 0.74026983 0.7631374  0.         0.62651741 0.49447657\n",
            "  0.28991478 0.50698853 0.         0.41954141 0.1872796  0.41763125\n",
            "  0.31765676 0.55698682 0.         0.29886197 0.24212303 0.23860201\n",
            "  0.37587857 0.37376945 0.         0.42921779]\n",
            " [0.43478478 0.43297851 0.42717415 0.0657495  0.43328879 0.\n",
            "  0.         0.52279949 0.46456617 0.07758807 0.0721488  0.65742866\n",
            "  0.57795783 0.35855231 0.39393109 0.35422067 0.44452032 0.52964711\n",
            "  0.43473946 0.76813876 0.82785835 0.         0.96537572 0.42320972\n",
            "  0.00431845 0.41420251 0.         0.41954141 0.20703747 0.42639978\n",
            "  0.32582414 0.55698682 0.         0.29886197 0.24697865 0.23860201\n",
            "  0.3769301  0.37440584 0.         0.43780601]\n",
            " [0.4303963  0.43387445 0.43575199 0.06311891 0.43207616 0.\n",
            "  0.         0.47788691 0.43981375 0.07645345 0.07223033 0.65604554\n",
            "  0.57846717 0.32432676 0.39545451 0.35577287 0.44597756 0.51189277\n",
            "  0.43172636 0.71120302 0.8028602  0.         0.83624267 0.39167737\n",
            "  0.03740983 0.34784379 0.         0.43224891 0.22478114 0.42639978\n",
            "  0.3323579  0.55698682 0.         0.29886197 0.24383677 0.23860201\n",
            "  0.37797192 0.37506824 0.         0.43224891]\n",
            " [0.4282943  0.43242546 0.43020161 0.06592067 0.4319539  0.\n",
            "  0.         0.51155122 0.44242466 0.07762146 0.07243194 0.65615439\n",
            "  0.57889783 0.29388663 0.39674855 0.35709137 0.44721538 0.5162892\n",
            "  0.43068364 0.71167394 0.78315976 0.         0.73141666 0.34257921\n",
            "  0.03740983 0.29522062 0.         0.43224891 0.23929831 0.42115679\n",
            "  0.33698757 0.55698682 0.         0.         0.24610293 0.23860201\n",
            "  0.37899642 0.37575127 0.         0.43267083]\n",
            " [0.43070933 0.42681751 0.43062302 0.06708282 0.42808116 0.\n",
            "  0.         0.47460313 0.42117178 0.0764396  0.07247125 0.65465817\n",
            "  0.57905682 0.30057063 0.39715319 0.35750364 0.44760243 0.50160887\n",
            "  0.4276872  0.70709637 0.76144623 0.         0.714348   0.30201619\n",
            "  0.01228507 0.24913122 0.         0.43224891 0.25139562 0.4153016\n",
            "  0.34011113 0.55698682 0.         0.05669011 0.2397815  0.23860201\n",
            "  0.37998762 0.37644879 0.         0.42693604]\n",
            " [0.42370457 0.42740371 0.42489516 0.0769115  0.42522855 0.\n",
            "  0.         0.45474111 0.39139763 0.07514059 0.07237172 0.65398316\n",
            "  0.57910636 0.27772808 0.39723667 0.35758871 0.44768229 0.48267129\n",
            "  0.42477801 0.708084   0.74436088 0.         0.63392664 0.28209925\n",
            "  0.01181118 0.2110348  0.         0.43224891 0.26163149 0.41291535\n",
            "  0.34247725 0.55698682 0.         0.10712712 0.23607149 0.23860201\n",
            "  0.38093413 0.37715456 0.         0.42459886]\n",
            " [0.42421325 0.40296993 0.42256081 0.06844316 0.40950261 0.\n",
            "  0.         0.45543836 0.36639061 0.07394252 0.07217079 0.648076\n",
            "  0.57844823 0.34858273 0.39499798 0.35530772 0.44554087 0.47145139\n",
            "  0.40935994 0.56593212 0.57635465 0.         0.57185783 0.25173463\n",
            "  0.00638725 0.17846635 0.         0.40248708 0.26713788 0.41291535\n",
            "  0.34450528 0.55698682 0.         0.15645358 0.21957427 0.23860201\n",
            "  0.38180029 0.37785901 0.         0.40248708]\n",
            " [0.40194658 0.39913725 0.40047575 0.06465042 0.40741374 0.\n",
            "  0.         0.54273167 0.39194794 0.07509539 0.07210388 0.64932354\n",
            "  0.57802165 0.34607286 0.39353855 0.35382072 0.44414484 0.51010616\n",
            "  0.40226132 0.6422846  0.5115409  0.         0.51272684 0.22570488\n",
            "  0.00638725 0.1508545  0.64982173 0.4072059  0.2723943  0.41291535\n",
            "  0.34626285 0.57234227 1.         0.19170956 0.22633514 0.23860201\n",
            "  0.38257628 0.37855317 0.         0.4072059 ]\n",
            " [0.40109123 0.40559139 0.40518886 0.06857829 0.40451396 0.\n",
            "  0.         0.48072054 0.38215929 0.0738957  0.07193975 0.64842178\n",
            "  0.5775529  0.3194246  0.39195442 0.35220667 0.44262953 0.50381471\n",
            "  0.40304056 0.72416586 0.53742165 0.         0.46158865 0.35161186\n",
            "  0.27358141 0.1572344  0.67836652 0.4072059  0.2769935  0.39179033\n",
            "  0.34579797 0.55984688 1.         0.19121049 0.22362326 0.50383151\n",
            "  0.38325677 0.37922896 0.         0.40390824]\n",
            " [0.40451816 0.38945885 0.40189519 0.06967737 0.40149603 0.\n",
            "  0.         0.51282842 0.38950143 0.07268292 0.07169291 0.64756954\n",
            "  0.57705317 0.35956556 0.39028384 0.35050453 0.44103154 0.51711025\n",
            "  0.3977398  0.65194184 0.49001862 0.         0.46268803 0.31766554\n",
            "  0.2248449  0.15746601 0.60303224 0.4072059  0.28105144 0.38865593\n",
            "  0.3451076  0.54993017 0.69235666 0.27776713 0.21725164 0.56176455\n",
            "  0.38383946 0.37987926 0.         0.40083829]\n",
            " [0.39316963 0.3812792  0.39882895 0.06664138 0.38624542 0.\n",
            "  0.         0.45502935 0.36835418 0.07150632 0.07137868 0.64180537\n",
            "  0.5760349  0.38517572 0.38692298 0.34708018 0.43781669 0.49497127\n",
            "  0.38410474 0.62677607 0.42476603 0.         0.41931382 0.28788631\n",
            "  0.2248449  0.15766775 0.67822105 0.37952034 0.2822763  0.38865593\n",
            "  0.34449396 0.44274268 0.1027618  0.32774564 0.20519886 0.64443122\n",
            "  0.38430705 0.38049586 0.         0.37952034]\n",
            " [0.39088869 0.37792774 0.37753677 0.05745233 0.39388557 0.\n",
            "  0.         0.55751167 0.39690866 0.0725734  0.07118359 0.64660665\n",
            "  0.57559394 0.41113296 0.38556629 0.34569785 0.43651894 0.53671425\n",
            "  0.38858728 0.68664882 0.4220156  0.         0.38104198 0.2616102\n",
            "  0.2248449  0.15784465 0.75959643 0.3985621  0.28492729 0.38865593\n",
            "  0.34394494 0.46925397 0.05811519 0.37170258 0.21910975 0.4853032\n",
            "  0.38466935 0.38107278 0.         0.3985621 ]\n",
            " [0.40095706 0.39709099 0.39655551 0.05629919 0.40192985 0.\n",
            "  0.         0.54449529 0.41660638 0.07362673 0.07108981 0.64860407\n",
            "  0.57538693 0.40659507 0.38503698 0.34515854 0.43601263 0.55732718\n",
            "  0.40110729 0.81508597 0.53436302 0.         0.34709851 0.4169121\n",
            "  0.46878901 0.18218407 0.76586582 0.40678953 0.28795263 0.38865593\n",
            "  0.34345084 0.51576384 0.04730665 0.40943693 0.22679652 0.42887987\n",
            "  0.38494281 0.3816066  0.         0.40678953]\n",
            " [0.40549649 0.40743303 0.404773   0.0614883  0.40455191 0.\n",
            "  0.         0.48415664 0.40806215 0.07251155 0.07092267 0.64858147\n",
            "  0.5751989  0.38541348 0.38455464 0.37894638 0.40336922 0.53668848\n",
            "  0.40605367 0.74588931 0.57397225 0.         0.3168566  0.53312698\n",
            "  0.5896168  0.21545237 0.69637657 0.40678953 0.2906897  0.3946414\n",
            "  0.34344036 0.52427891 0.04067133 0.42441385 0.22319011 0.42935776\n",
            "  0.38514098 0.38209567 0.         0.40670069]\n",
            " [0.40838677 0.40468438 0.40468426 0.07120888 0.41130553 0.\n",
            "  0.         0.56216074 0.43336821 0.07374259 0.07086091 0.65105211\n",
            "  0.57524808 0.38256164 0.38481097 0.37880516 0.40399218 0.56631446\n",
            "  0.40903154 0.71692585 0.58459532 0.         0.3496126  0.48760818\n",
            "  0.52502081 0.23897286 0.62504128 0.40678953 0.29317781 0.40362533\n",
            "  0.34405746 0.52246466 0.034869   0.40686527 0.23149207 0.38202724\n",
            "  0.38528134 0.38254029 0.         0.41549987]] 0.41516679373146975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIEl8prR7N1o",
        "colab_type": "text"
      },
      "source": [
        "MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNyP0dVGCyWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(layers):\n",
        "    d = 0.3\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
        "    model.add(Dropout(d))\n",
        "        \n",
        "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
        "    model.add(Dropout(d))\n",
        "        \n",
        "    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n",
        "    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n",
        "    \n",
        "    # adam = keras.optimizers.Adam(decay=0.2)\n",
        "        \n",
        "    start = time.time()\n",
        "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
        "    print(\"Compilation Time : \", time.time() - start)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpA091Ob7GfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(layers):\n",
        "    d = 0.3\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(LSTM(4, activation='relu', input_shape=(1, look_back), return_sequences=False))\n",
        "    model.add(Dropout(d))\n",
        "        \n",
        "    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))        \n",
        "    \n",
        "    #adam = keras.optimizers.Adam(decay=0.2)\n",
        "        \n",
        "    start = time.time()\n",
        "    model.compile(loss='mse', optimizer=optimizers.Adam(lr=0.001), metrics=['mse'])\n",
        "    print(\"Compilation Time : \", time.time() - start)\n",
        "    return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LONFq8Gl7Pfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(look_back)\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "history = model.fit(trainX,trainY,batch_size=100,epochs=500,validation_split=0.2,callbacks=[clr_triangular], verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XRKtibQC_rG",
        "colab_type": "code",
        "outputId": "76fc1c1b-de4a-43bf-9769-6c369779ce8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3128
        }
      },
      "source": [
        "model = build_model([40,window,1])\n",
        "clr_triangular = CyclicLR(mode='triangular')\n",
        "model.fit(X_train,y_train,batch_size=512,epochs=90,validation_split=0.2,callbacks=[clr_triangular],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compilation Time :  0.029506683349609375\n",
            "Train on 1607 samples, validate on 402 samples\n",
            "Epoch 1/90\n",
            "1607/1607 [==============================] - 6s 4ms/step - loss: 0.0664 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
            "Epoch 2/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0155 - val_acc: 0.0000e+00\n",
            "Epoch 3/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0095 - acc: 0.0000e+00 - val_loss: 0.0439 - val_acc: 0.0000e+00\n",
            "Epoch 4/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
            "Epoch 5/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0086 - acc: 0.0000e+00 - val_loss: 0.0138 - val_acc: 0.0000e+00\n",
            "Epoch 6/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0091 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
            "Epoch 7/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
            "Epoch 8/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0082 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0000e+00\n",
            "Epoch 9/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0075 - acc: 0.0000e+00 - val_loss: 0.0167 - val_acc: 0.0000e+00\n",
            "Epoch 10/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0065 - acc: 0.0000e+00 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
            "Epoch 11/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
            "Epoch 12/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
            "Epoch 13/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00\n",
            "Epoch 14/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 6.5548e-04 - val_acc: 0.0000e+00\n",
            "Epoch 15/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 9.6861e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 16/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 7.8988e-04 - acc: 0.0000e+00 - val_loss: 3.0263e-04 - val_acc: 0.0000e+00\n",
            "Epoch 17/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 7.4731e-04 - acc: 0.0000e+00 - val_loss: 6.2558e-04 - val_acc: 0.0000e+00\n",
            "Epoch 18/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 6.2936e-04 - acc: 0.0000e+00 - val_loss: 2.5860e-04 - val_acc: 0.0000e+00\n",
            "Epoch 19/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 6.0042e-04 - acc: 0.0000e+00 - val_loss: 3.0515e-04 - val_acc: 0.0000e+00\n",
            "Epoch 20/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 5.9325e-04 - acc: 0.0000e+00 - val_loss: 3.3269e-04 - val_acc: 0.0000e+00\n",
            "Epoch 21/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 5.1842e-04 - acc: 0.0000e+00 - val_loss: 2.5591e-04 - val_acc: 0.0000e+00\n",
            "Epoch 22/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 5.4019e-04 - acc: 0.0000e+00 - val_loss: 2.7038e-04 - val_acc: 0.0000e+00\n",
            "Epoch 23/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 5.7055e-04 - acc: 0.0000e+00 - val_loss: 2.2051e-04 - val_acc: 0.0000e+00\n",
            "Epoch 24/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 5.2282e-04 - acc: 0.0000e+00 - val_loss: 2.7828e-04 - val_acc: 0.0000e+00\n",
            "Epoch 25/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.5953e-04 - acc: 0.0000e+00 - val_loss: 2.6787e-04 - val_acc: 0.0000e+00\n",
            "Epoch 26/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.6829e-04 - acc: 0.0000e+00 - val_loss: 3.1186e-04 - val_acc: 0.0000e+00\n",
            "Epoch 27/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.8118e-04 - acc: 0.0000e+00 - val_loss: 2.2407e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.4854e-04 - acc: 0.0000e+00 - val_loss: 2.2186e-04 - val_acc: 0.0000e+00\n",
            "Epoch 29/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.5391e-04 - acc: 0.0000e+00 - val_loss: 2.2211e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.5082e-04 - acc: 0.0000e+00 - val_loss: 2.1902e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 5.0960e-04 - acc: 0.0000e+00 - val_loss: 2.6163e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.6809e-04 - acc: 0.0000e+00 - val_loss: 2.0247e-04 - val_acc: 0.0000e+00\n",
            "Epoch 33/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.3726e-04 - acc: 0.0000e+00 - val_loss: 2.1647e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.4139e-04 - acc: 0.0000e+00 - val_loss: 3.6922e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.4486e-04 - acc: 0.0000e+00 - val_loss: 2.2199e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.9869e-04 - acc: 0.0000e+00 - val_loss: 1.8863e-04 - val_acc: 0.0000e+00\n",
            "Epoch 37/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.6827e-04 - acc: 0.0000e+00 - val_loss: 2.3923e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.8402e-04 - acc: 0.0000e+00 - val_loss: 1.8187e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.7625e-04 - acc: 0.0000e+00 - val_loss: 1.9313e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.7158e-04 - acc: 0.0000e+00 - val_loss: 5.8894e-04 - val_acc: 0.0000e+00\n",
            "Epoch 41/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.2510e-04 - acc: 0.0000e+00 - val_loss: 1.9216e-04 - val_acc: 0.0000e+00\n",
            "Epoch 42/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.9088e-04 - acc: 0.0000e+00 - val_loss: 7.6959e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 5.2013e-04 - acc: 0.0000e+00 - val_loss: 4.1654e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.2925e-04 - acc: 0.0000e+00 - val_loss: 2.5326e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.6042e-04 - acc: 0.0000e+00 - val_loss: 3.8567e-04 - val_acc: 0.0000e+00\n",
            "Epoch 46/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.7494e-04 - acc: 0.0000e+00 - val_loss: 1.9186e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 4.1670e-04 - acc: 0.0000e+00 - val_loss: 2.4487e-04 - val_acc: 0.0000e+00\n",
            "Epoch 48/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.7082e-04 - acc: 0.0000e+00 - val_loss: 2.1816e-04 - val_acc: 0.0000e+00\n",
            "Epoch 49/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.4852e-04 - acc: 0.0000e+00 - val_loss: 1.8447e-04 - val_acc: 0.0000e+00\n",
            "Epoch 50/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.8465e-04 - acc: 0.0000e+00 - val_loss: 2.1718e-04 - val_acc: 0.0000e+00\n",
            "Epoch 51/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.2094e-04 - acc: 0.0000e+00 - val_loss: 1.7947e-04 - val_acc: 0.0000e+00\n",
            "Epoch 52/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.2483e-04 - acc: 0.0000e+00 - val_loss: 1.9069e-04 - val_acc: 0.0000e+00\n",
            "Epoch 53/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.7417e-04 - acc: 0.0000e+00 - val_loss: 5.1075e-04 - val_acc: 0.0000e+00\n",
            "Epoch 54/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.8581e-04 - acc: 0.0000e+00 - val_loss: 3.0471e-04 - val_acc: 0.0000e+00\n",
            "Epoch 55/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.5218e-04 - acc: 0.0000e+00 - val_loss: 1.6406e-04 - val_acc: 0.0000e+00\n",
            "Epoch 56/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.4390e-04 - acc: 0.0000e+00 - val_loss: 1.5671e-04 - val_acc: 0.0000e+00\n",
            "Epoch 57/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.4756e-04 - acc: 0.0000e+00 - val_loss: 4.1336e-04 - val_acc: 0.0000e+00\n",
            "Epoch 58/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.7667e-04 - acc: 0.0000e+00 - val_loss: 1.6544e-04 - val_acc: 0.0000e+00\n",
            "Epoch 59/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.5996e-04 - acc: 0.0000e+00 - val_loss: 1.7391e-04 - val_acc: 0.0000e+00\n",
            "Epoch 60/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.6469e-04 - acc: 0.0000e+00 - val_loss: 3.4886e-04 - val_acc: 0.0000e+00\n",
            "Epoch 61/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.6156e-04 - acc: 0.0000e+00 - val_loss: 2.5494e-04 - val_acc: 0.0000e+00\n",
            "Epoch 62/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.2682e-04 - acc: 0.0000e+00 - val_loss: 1.6792e-04 - val_acc: 0.0000e+00\n",
            "Epoch 63/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.1423e-04 - acc: 0.0000e+00 - val_loss: 2.7308e-04 - val_acc: 0.0000e+00\n",
            "Epoch 64/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.3595e-04 - acc: 0.0000e+00 - val_loss: 1.7573e-04 - val_acc: 0.0000e+00\n",
            "Epoch 65/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.9764e-04 - acc: 0.0000e+00 - val_loss: 1.7198e-04 - val_acc: 0.0000e+00\n",
            "Epoch 66/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.5244e-04 - acc: 0.0000e+00 - val_loss: 3.1069e-04 - val_acc: 0.0000e+00\n",
            "Epoch 67/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.5381e-04 - acc: 0.0000e+00 - val_loss: 1.7324e-04 - val_acc: 0.0000e+00\n",
            "Epoch 68/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.3555e-04 - acc: 0.0000e+00 - val_loss: 2.6207e-04 - val_acc: 0.0000e+00\n",
            "Epoch 69/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.2640e-04 - acc: 0.0000e+00 - val_loss: 3.8843e-04 - val_acc: 0.0000e+00\n",
            "Epoch 70/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.5715e-04 - acc: 0.0000e+00 - val_loss: 1.7561e-04 - val_acc: 0.0000e+00\n",
            "Epoch 71/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.0732e-04 - acc: 0.0000e+00 - val_loss: 3.9197e-04 - val_acc: 0.0000e+00\n",
            "Epoch 72/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.7311e-04 - acc: 0.0000e+00 - val_loss: 1.9846e-04 - val_acc: 0.0000e+00\n",
            "Epoch 73/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.4477e-04 - acc: 0.0000e+00 - val_loss: 1.5129e-04 - val_acc: 0.0000e+00\n",
            "Epoch 74/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.5005e-04 - acc: 0.0000e+00 - val_loss: 2.8706e-04 - val_acc: 0.0000e+00\n",
            "Epoch 75/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.4804e-04 - acc: 0.0000e+00 - val_loss: 1.8993e-04 - val_acc: 0.0000e+00\n",
            "Epoch 76/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.1532e-04 - acc: 0.0000e+00 - val_loss: 1.7328e-04 - val_acc: 0.0000e+00\n",
            "Epoch 77/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.9813e-04 - acc: 0.0000e+00 - val_loss: 1.6420e-04 - val_acc: 0.0000e+00\n",
            "Epoch 78/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.9802e-04 - acc: 0.0000e+00 - val_loss: 1.8265e-04 - val_acc: 0.0000e+00\n",
            "Epoch 79/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.8497e-04 - acc: 0.0000e+00 - val_loss: 3.0331e-04 - val_acc: 0.0000e+00\n",
            "Epoch 80/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.8012e-04 - acc: 0.0000e+00 - val_loss: 2.5073e-04 - val_acc: 0.0000e+00\n",
            "Epoch 81/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.1263e-04 - acc: 0.0000e+00 - val_loss: 1.7063e-04 - val_acc: 0.0000e+00\n",
            "Epoch 82/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.0708e-04 - acc: 0.0000e+00 - val_loss: 3.1383e-04 - val_acc: 0.0000e+00\n",
            "Epoch 83/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.9445e-04 - acc: 0.0000e+00 - val_loss: 2.6352e-04 - val_acc: 0.0000e+00\n",
            "Epoch 84/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.9988e-04 - acc: 0.0000e+00 - val_loss: 1.5066e-04 - val_acc: 0.0000e+00\n",
            "Epoch 85/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.5982e-04 - acc: 0.0000e+00 - val_loss: 2.2407e-04 - val_acc: 0.0000e+00\n",
            "Epoch 86/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.6081e-04 - acc: 0.0000e+00 - val_loss: 1.8357e-04 - val_acc: 0.0000e+00\n",
            "Epoch 87/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.9095e-04 - acc: 0.0000e+00 - val_loss: 1.7244e-04 - val_acc: 0.0000e+00\n",
            "Epoch 88/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.9302e-04 - acc: 0.0000e+00 - val_loss: 1.9125e-04 - val_acc: 0.0000e+00\n",
            "Epoch 89/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 2.6491e-04 - acc: 0.0000e+00 - val_loss: 1.7057e-04 - val_acc: 0.0000e+00\n",
            "Epoch 90/90\n",
            "1607/1607 [==============================] - 5s 3ms/step - loss: 3.0761e-04 - acc: 0.0000e+00 - val_loss: 2.0557e-04 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f808dcfd160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1FSZqSs7XHZ",
        "colab_type": "text"
      },
      "source": [
        "PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK9hfQi-Dvq5",
        "colab_type": "code",
        "outputId": "7719291d-5909-403b-81d5-66535c6ed48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print(X_test[-1])\n",
        "diff=[]\n",
        "ratio=[]\n",
        "p = model.predict(X_test)\n",
        "print (p.shape)\n",
        "# for each data index in test data\n",
        "for u in range(len(y_test)):\n",
        "    # pr = prediction day u\n",
        "    pr = p[u][0]\n",
        "    # (y_test day u / pr) - 1\n",
        "    ratio.append((y_test[u]/pr)-1)\n",
        "    diff.append(abs(y_test[u]- pr))\n",
        "    # print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))\n",
        "    # Last day prediction\n",
        "    # print(p[-1]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2387, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCHHmw2iD09D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pdr.get_data_yahoo('^GSPC', start=datetime.datetime(2000, 1, 4), end=datetime.datetime(2017, 7, 27))\n",
        "df = df.drop(['Close'],1)\n",
        "df.columns = ['high', 'low', 'open', 'volume', 'adj close']\n",
        "\n",
        "def denormalize(df, normalized_value): \n",
        "    df = df['adj close'].values.reshape(-1,1)\n",
        "    normalized_value = normalized_value.reshape(-1,1)\n",
        "    \n",
        "    #return df.shape, p.shape\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    a = min_max_scaler.fit_transform(df)\n",
        "    new = min_max_scaler.inverse_transform(normalized_value)\n",
        "    return new\n",
        "\n",
        "newp = denormalize(df, p)\n",
        "newy_test = denormalize(df, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUmybA-9D0na",
        "colab_type": "code",
        "outputId": "d42b25ff-a57f-49dc-b4c3-ed3981e378ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def model_score(model, X_train, y_train, X_test, y_test):\n",
        "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
        "\n",
        "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
        "    return trainScore[0], testScore[0]\n",
        "\n",
        "\n",
        "model_score(model, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Score: 0.00014 MSE (0.01 RMSE)\n",
            "Test Score: 0.00620 MSE (0.08 RMSE)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.00014017713939374235, 0.006202261507800641)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8tvist6ErCX",
        "colab_type": "code",
        "outputId": "2c30f170-4513-4800-8f67-64e1830a66a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt2\n",
        "\n",
        "plt2.plot(newp,color='red', label='Prediction')\n",
        "plt2.plot(newy_test,color='blue', label='Actual')\n",
        "plt2.legend(loc='best')\n",
        "plt2.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTEkYhmEYMfl/t2rE3ScUnKkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrZ12UDWE8kI",
        "colab_type": "code",
        "outputId": "7ead55e1-ef65-4f88-f955-5857191ed241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "pt = model.predict(X_train)\n",
        "new_pt = denormalize(df, pt)\n",
        "newy_train = denormalize(df, y_train)\n",
        "\n",
        "plt2.plot(new_pt,color='red', label='Prediction')\n",
        "plt2.plot(newy_train,color='blue', label='Actual')\n",
        "plt2.legend(loc='best')\n",
        "plt2.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEN-9_0nEqsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D9w3nHv7b5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt2\n",
        "\n",
        "plt2.plot(model.predict(trainX),color='red', label='Prediction')\n",
        "plt2.plot(trainY,color='blue', label='Actual')\n",
        "plt2.legend(loc='best')\n",
        "plt2.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0bQz3fx7dZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt2\n",
        "\n",
        "\n",
        "plt2.plot(model.predict(testX),color='red', label='Prediction')\n",
        "plt2.plot(testY,color='blue', label='Actual')\n",
        "plt2.legend(loc='best')\n",
        "plt2.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}